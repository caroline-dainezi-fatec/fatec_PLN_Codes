{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7QPUr4RBeAvy0Wi9tds7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caroline-dainezi-fatec/fatec_PLN_Codes/blob/main/Aula8_IntroducaoMLParaPLN/%5BPLN%5D_Aula_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 8 - Introdução a Machine Learning para PLN"
      ],
      "metadata": {
        "id": "hc8ZQY0cLJTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01 - Aplicação do modelo de Naives em um texto\n",
        "\n",
        "### Explicação do Código\n",
        "O código implementa um classificador probabilístico simples para prever sentimentos (positivo ou negativo) em frases curtas.\n",
        "\n",
        "1. Na criação do Corpus, é feita uma lista de frases categorizadas em positivo ou negativo.\n",
        "\n",
        "2. A função `preprocess_text` converte textos para minúsculas, remove caracteres não alfabéticos e retorna uma lista de palavras pré-processadas.\n",
        "\n",
        "3. Passo 3 - Calculando Probabilidades\n",
        "\n",
        "  O passo 3 realiza a contagem de frequências e o cálculo das probabilidades a priori e condicionais (etapas essenciais para classificar textos com base no modelo probabilístico).\n",
        "\n",
        "  - Variáveis iniciais:\n",
        "    - `class_counts`: Um `Counter` que armazena o número de exemplos em cada classe (positivo ou negativo).\n",
        "    - `word_counts`: Registra as frequências das palavras em cada classe.\n",
        "    - `total_words`: Mantém a contagem total de palavras em cada classe.\n",
        "\n",
        "  - Para cada frase do corpus (`preprocessed_corpus`), o loop `for`:\n",
        "      - Incrementa o contador de exemplos para a classe correspondente em `class_counts`.\n",
        "      - Depois, para cada palavra da frase:\n",
        "        - Incrementa a contagem da palavra na classe em `word_counts`.\n",
        "        - Atualiza o total de palavras da classe em `total_words`.\n",
        "\n",
        "  - A variável `prior_probabilities` calcula a probabilidade de ocorrência de cada classe com base na proporção de exemplos daquela classe no corpus.\n",
        "\n",
        "  - A função `conditional_probability` retorna a probabilidade de uma palavra estar associada a uma classe específica, considerando suavização de Laplace para evitar probabilidades zero. Seus parâmetros são:\n",
        "    - `word`: A palavra a ser avaliada.\n",
        "    - `label`: A classe associada (*positivo* ou *negativo*).\n",
        "    - `alpha`: O fator de suavização (valor padrão é 1).\n",
        "\n",
        "4. Passo 4 - Classificar um Novo Texto\n",
        "\n",
        "  O passo 4 implementa o processo de classificação de um novo texto utilizando as probabilidades a priori e condicionais calculadas no passo 3.\n",
        "\n",
        "  - Pré-processamento do texto:\n",
        "    - A função `predict` recebe um texto como entrada.\n",
        "    - O texto é pré-processado com a função `preprocess_text` do passo 2 para tokenização e normalização.\n",
        "\n",
        "  - Um dicionário `probabilities` é inicializado para armazenar a probabilidade de o texto pertencer a cada classe.\n",
        "    - Para cada classe existente em `class_counts`, a probabilidade inicial da classe é definida como sua probabilidade a priori (`prior_probabilities` do passo 3).\n",
        "    - Para cada palavra no texto, multiplica a probabilidade da classe pela probabilidade condicional da palavra, calculada com a função `conditional_probability`.\n",
        "\n",
        "  - A classe com a maior probabilidade no dicionário `probabilities` é selecionada como a predição final.\n",
        "    - A função retorna a classe predita e as probabilidades calculadas para todas as classes.\n",
        "\n",
        "5. Com o texto \"*Eu amo resolver bugs*\", o classificador prevê o rótulo positivo e exibe as probabilidades calculadas."
      ],
      "metadata": {
        "id": "NB3S6MTyT2e1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY7LTXk2LDdN",
        "outputId": "f4e28640-5c0f-4895-bc8d-89bf000ebb20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo')]\n",
            "Texto: \"Eu amo resolver bugs\"\n",
            "Classe prevista: positivo\n",
            "Probabilidades:\n",
            " positivo: 0.009600000000000001\n",
            " negativo: 0.0078125\n"
          ]
        }
      ],
      "source": [
        "# Passo 1 - Criar o Corpus\n",
        "\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\", \"positivo\"),\n",
        "    (\"Eu odeio bugs\", \"negativo\"),\n",
        "    (\"Amo resolver problemas\", \"positivo\"),\n",
        "    (\"Odeio erros\", \"negativo\")\n",
        "]\n",
        "\n",
        "# Passo 2 - Processar o Texto\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "preprocessed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(preprocessed_corpus)\n",
        "\n",
        "# Passo 3 - Calculando probabilidades\n",
        "  # este passo precisa estar explicado\n",
        "class_counts = Counter() # Contagem das classes\n",
        "word_counts = defaultdict(Counter)\n",
        "total_words = defaultdict(int)\n",
        "\n",
        "for words, label in preprocessed_corpus:\n",
        "  class_counts[label] += 1\n",
        "  for word in words:\n",
        "    word_counts[label][word] += 1\n",
        "    total_words[label]\n",
        "\n",
        "total_examples = sum(class_counts.values())\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "  return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "# Passo 4 - Classificar um novo Texto\n",
        "  # este passo precisa estar explicado\n",
        "def predict(text):\n",
        "  words = preprocess_text(text)\n",
        "  probabilities = {}\n",
        "\n",
        "  for label in class_counts.keys():\n",
        "    probabilities[label] = prior_probabilities[label]\n",
        "    for word in words:\n",
        "      probabilities[label] *= conditional_probability(word, label)\n",
        "  return max(probabilities, key=probabilities.get), probabilities\n",
        "\n",
        "# Passo 5 - Teste com um novo texto\n",
        "novo_texto = \"Eu amo resolver bugs\"\n",
        "classe, probs = predict(novo_texto)\n",
        "\n",
        "print(f'Texto: \"{novo_texto}\"')\n",
        "print(f'Classe prevista: {classe}')\n",
        "print(f'Probabilidades:')\n",
        "for label, prob in probs.items():\n",
        "  print(f\" {label}: {prob}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 2 - Modelo de SVM\n",
        "\n",
        "### Explicação do código\n",
        "\n",
        "1. Primeiro, são importadas as bibliotecas necessárias para a implementação do modelo de classificação de texto utilizando o método SVC: `TfidfVectorizer`, `SVC`, `train_test_split` e `classification_report`.\n",
        "\n",
        "2. O código define um conjunto de dados de exemplo (corpus) e suas respectivas classes, que indicam se a frase é \"positivo\" ou \"negativo\".\n",
        "\n",
        "3. Transforma os textos em vetores numéricos para que possam ser usados pelo modelo de machine learning:\n",
        "\n",
        "  - O `TfidfVectorizer` converte cada documento em um vetor baseado na técnica TF-IDF, que considera a importância das palavras dentro do corpus.\n",
        "  - `X`: O conjunto de dados transformados em vetores, pronto para ser usado no treinamento.\n",
        "  - `y`: A variável com as classes correspondentes a cada frase.\n",
        "\n",
        "4. Os dados são divididos entre treinamento e teste e o modelo é treinado:\n",
        "\n",
        "  - `train_test_split` divide os dados `X` e `y` em dois conjuntos: 70% para treinamento e 30% para teste (`test_size=0.3`).\n",
        "  - O modelo SVM (`SVC(kernel='linear)`) é treinado com os dados de treinamento `X_train` e `y_train`.\n",
        "\n",
        "5. Avalia o modelo no conjunto de teste `X_test`, e o `classification_report` é utilizado para gerar um relatório que mostra a performance do modelo."
      ],
      "metadata": {
        "id": "-wFFIaygT7ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 - Importação das bibliotecas a serem utilizadas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Passo 2 - Dados de Exemplo\n",
        "corpus = [\n",
        "    \"Eu amo PLN\", \"Eu odeio bugs\", \"Eu amo resolver problemas\",\n",
        "    \"Odeio erros\", \"Amo programação\", \"Não gosto de falhas\"\n",
        "]\n",
        "classes = [\"negativo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"]\n",
        "\n",
        "# Passo 3 - Pré-processamento e vetorização\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "y = classes\n",
        "\n",
        "# Passo 4 - Dividir os dados e terinar o modelo\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Passo 5 - Avaliar o modelo\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQLIo91BT_Jv",
        "outputId": "be3b3e93-c2f2-4b82-d1fa-e754bfdc3bcb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      0.50      0.67         2\n",
            "    positivo       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.50      0.25      0.33         2\n",
            "weighted avg       1.00      0.50      0.67         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 3 - Comparação dos dois modelos\n",
        "\n",
        "### Explicação do código\n",
        "\n",
        "1. São importadas as bibliotecas necessárias para o pré-processamento de texto e para a construção do modelo de classificação. Isso inclui a `TfidfVectorizer`, a `train_test_split`, a `MultinomialNB` (Naive Bayes) e `SVC` (SVM) para construir os modelos, e `classification_report`.\n",
        "\n",
        "2. Preparação dos Dados:\n",
        "  - O dataset de `movie_reviews` da biblioteca `NLTK` é carregado (resenhas de filmes rotuladas como \"positivo\" ou \"negativo\").\n",
        "  - Os documentos são coletados, onde cada texto é combinado com seu respectivo rótulo.\n",
        "  - Os textos e as classes são separados e as classes são transformadas para valores numéricos (0 para \"negativo\" e 1 para \"positivo\") usando o `LabelEncoder`.\n",
        "\n",
        "3. O `TfidfVectorizer` é configurado para limitar a 5.000 das palavras mais frequentes do corpus. Ele também é ajustado e aplicado aos textos de treinamento (`X_train`) e, em seguida, os textos de teste (`X_test`) são transformados.\n",
        "\n",
        "4. Ambos os modelos `MultinomialNB` (Naive Bayes) e `SVC` (SVM) são treinado com os dados de treino e fazem previsões sobre os dados de teste.\n",
        "\n",
        "5. Para cada modelo, as previsões são avaliadas usando `classification_report`, que gera métricas como precisão, recall e f1-score, permitindo comparar a performance de ambos os modelos no conjunto de teste."
      ],
      "metadata": {
        "id": "ifjorL1JVCf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar Bibliotecas\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "  # Baixar o dataset de exemplo\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "# 2. Preparação dos dados\n",
        "\n",
        "  # Coleta de textos e classes\n",
        "documents = [\n",
        "    (\" \".join(movie_reviews.words(fileid)), category)\n",
        "    for category in movie_reviews.categories()\n",
        "    for fileid in movie_reviews.fileids(category)\n",
        "]\n",
        "\n",
        "  # Separar textos e rótulos\n",
        "texts, labels = zip(*documents)\n",
        "\n",
        "  # Transformar rótulos (positivo/negativo) em 0 e 1\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "  # Dividir dados em treino e teste\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Representação do texto com TF-IDF\n",
        "  # Criar o vetorizador TF_IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000) # Limitar a 5.000 palavras mais comuns\n",
        "\n",
        "  # Ajustar e transformar os textos\n",
        "X_train = vectorizer.fit_transform(texts_train)\n",
        "X_test = vectorizer.transform(texts_test)\n",
        "\n",
        "# 4. Treinar os modelos\n",
        "\n",
        "  # Treinamento do Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, labels_train)\n",
        "\n",
        "  # Predição\n",
        "nb_predictions = nb_model.predict(X_test)\n",
        "\n",
        "  # Treinamento do SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, labels_train)\n",
        "\n",
        "  # Predição\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "\n",
        "# 5. Avaliação\n",
        "\n",
        "  # Avaliação do Naive Bayes\n",
        "print(\"Naive Bayes Performance:\")\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "\n",
        "  # Avaliação do SVM\n",
        "print(\"SVM Performance:\")\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiUto6gzVE-A",
        "outputId": "1987d474-825c-4a20-e875-f0d496252e2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "SVM Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}